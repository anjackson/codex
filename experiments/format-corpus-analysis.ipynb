{
 "metadata": {
  "name": "",
  "signature": "sha256:c37d1cc476c2c3bc30a4d5a59a14a4a4788e64516d82527bc6c3c3138460acad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Format Corpus Analysis\n",
      "======================\n",
      "\n",
      "Here, we can run Python scripts to scan through the contents of the [format corpus](https://github.com/openplanets/format-corpus/), invoking various tools and analysing the results.\n",
      "\n",
      "Using an [IPython Notebook](http://ipython.org/notebook.html) makes it very easy to regenerate the results by [re-running](https://github.com/paulgb/runipy) these analyses as part of a [continious integration process](https://travis-ci.org/openplanets/format-corpus). Furthermore, because it's an IPython Notebook it generates output that is easy to publish on the web as static pages.\n",
      "\n",
      "Outline of the process\n",
      "----------------------\n",
      "\n",
      "### 1. Update the remote corpora\n",
      "\n",
      "Where appropriate, the format corpus pull existing corpora by remote reference rather than duplicating them in the main repository. Therefore, the first step is to create/update the local copies of those resources.\n",
      "\n",
      "### 2. Run the tools\n",
      "\n",
      "We then run various tools of interest, and collect the results.\n",
      "\n",
      "### 3. Summarise the results\n",
      "\n",
      "We then summarise the results from the various tools.\n",
      "\n",
      "### 4. Compare with previous results\n",
      "\n",
      "We take the latest results and combine them with earlier sets of results, in order to see how things have changed over time.\n",
      "\n",
      "### 5. Generate website\n",
      "\n",
      "The data and graphs generated in this way are then used to generate a static website generated via Jekyll.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import subprocess\n",
      "import time\n",
      "\n",
      "def run_command(cmd):\n",
      "    '''given shell command, returns communication tuple of stdout and stderr'''\n",
      "    return subprocess.Popen(cmd, \n",
      "                            stdout=subprocess.PIPE, \n",
      "                            stderr=subprocess.PIPE, \n",
      "                            stdin=subprocess.PIPE)\n",
      "\n",
      "def run_tika(fp,out_fp):\n",
      "    start_time = os.times()[4]\n",
      "    p = run_command([\"tika\", \"-m\", fp])\n",
      "    of = open(out_fp+\".out\",'wb')\n",
      "    tika_type = None\n",
      "    while p.poll() is None:\n",
      "        line = p.stdout.readline()\n",
      "        of.write(line)\n",
      "        # Convert bytes to string, as UTF-8:\n",
      "        line = line.decode()\n",
      "        if \"Content-Type\" in line:\n",
      "            tika_type = line.rstrip().split(':')[1].strip()\n",
      "    of.close()\n",
      "    # Determine run-time:\n",
      "    end_time = os.times()[4]\n",
      "    run_time = end_time - start_time\n",
      "    # Check for stderr\n",
      "    errs = p.stderr.readlines()\n",
      "    has_stderr = False\n",
      "    if len(errs) > 0:\n",
      "        ef = open(out_fp+\".err\",'wb')\n",
      "        ef.writelines(errs)\n",
      "        ef.close()\n",
      "        has_stderr = True\n",
      "    # Note return code:\n",
      "    #print(p.returncode)\n",
      "    # Return:\n",
      "    return { 'type': tika_type, 'returncode': p.returncode, 'has_stderr': has_stderr, 'duration': run_time }\n",
      "\n",
      "\n",
      "prefix = '/Users/andy/Documents/workspace/format-corpus/'\n",
      "indir = prefix+'corpora/'\n",
      "outdir = prefix+'tool-output/tika/'\n",
      "count = 0\n",
      "for root, dirs, filenames in os.walk(indir):\n",
      "    rel_path = root.replace(indir, \"\")\n",
      "    out_name = rel_path.replace(\"/\",\".\")\n",
      "    \n",
      "    for f in filenames:\n",
      "        # Set up input and output filenames:\n",
      "        fp = os.path.join(root, f)\n",
      "        rel_fp = os.path.join(rel_path,f)\n",
      "        out_fp = os.path.join(outdir,out_name+\".\"+f)\n",
      "        out_fp = out_fp.replace(\" \",\"_\")\n",
      "        # Run tools\n",
      "        tika = run_tika(fp,out_fp)\n",
      "        print(\"%s\\t%s\\t%s\\t%s\\t%s\" % (rel_fp, tika['type'], tika['returncode'], tika['has_stderr'], tika['duration']) )\n",
      "        # Count files processed:\n",
      "        count+=1\n",
      "        # Only process one folder per file right now:\n",
      "        break\n",
      "\n",
      "    if count >= 10:\n",
      "        break\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Curation outline3.nmind.tar\tapplication/x-tar\t0\tFalse\t1.7300000190734863\n",
        "compression-resolution/00000019.300.tif\timage/tiff\t0\tFalse\t2.6500000953674316"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "desktop-publishing/InDesign/Neddy_Flyer_ft_HeatherRyan.jpg\timage/jpeg\t0\tFalse\t1.2899999618530273"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ebooks/Aesops-Fables.azw\ttext/html; charset=windows-1252\t0\tFalse\t1.5699999332427979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ebooks/calibre 0.8.57/.DS_Store\tapplication/octet-stream\t0\tFalse\t1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ebooks/calibre 0.9.0/create-variations.sh\ttext/plain; charset=ISO-8859-1\t0\tFalse\t1.0900001525878906"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ebooks/iBooks Author 1.1 (190)/lorem-ipsum-openprintcopypw.pdf\tNone\t1\tTrue\t1.2899999618530273"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ebooks/iBooks Author 2.0 (327)/lorem-ipsum-plus-image-updated-opencopyprintpw.pdf\tNone\t1\tTrue\t1.2400000095367432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "file-archive/readme.md\ttext/plain; charset=ISO-8859-1\t0\tFalse\t1.0999999046325684"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "file-archive/arj/MAPS.ARJ\tapplication/x-arj\t0\tFalse\t1.0199999809265137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}