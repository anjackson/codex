{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Fast Can You Hash\n",
    "--------------------\n",
    "\n",
    "This notebook runs some basic performance tests to determine how fast we can run data through the SHA-512 or MD5 algorithms.\n",
    "\n",
    "This test uses fairly large files in an attempt to minimise the effect of the operating system caching disk data in RAM.\n",
    "\n",
    "First we set up some functions that perform basic operations to compare:\n",
    "\n",
    "* `zero_to_null` just passes zeros through the CPU, and so is as fast as anything could possibly go.\n",
    "* `zero_to_hash` runs the zeros through SHA512, so is the fastest we can possibly hash (no disk I/O).\n",
    "* `zero_to_file` streams the zeros to a file - disk write I/O only, no hash.\n",
    "* `file_to_hash` hashes a file (created with `file_to_zero`), so this is disk read I/O and hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1000+0 records in\\n1000+0 records out\\n1048576000 bytes transferred in 2.143335 secs (489226400 bytes/sec)\\ne5c834fbdaa6bfd8eac5eb9404eefdd4\\n'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def zero_to_null(x):\n",
    "    return subprocess.check_output(\"dd if=/dev/zero of=/dev/null bs=1m count=1000\",stderr=subprocess.STDOUT,shell=True)\n",
    "\n",
    "def zero_to_hash(x):\n",
    "    return subprocess.check_output(\"dd if=/dev/zero bs=1m count=1000 | openssl dgst -sha512\",stderr=subprocess.STDOUT,shell=True)\n",
    "\n",
    "def zero_to_hash_md5(x):\n",
    "    return subprocess.check_output(\"dd if=/dev/zero bs=1m count=1000 | openssl dgst -md5\",stderr=subprocess.STDOUT,shell=True)\n",
    "\n",
    "def zero_to_file(x):\n",
    "    return subprocess.check_output(\"dd if=/dev/zero of=test.zero.%s bs=1m count=1000\" % x,stderr=subprocess.STDOUT,shell=True)\n",
    "\n",
    "def file_to_hash(x):\n",
    "    return subprocess.check_output(\"dd if=test.zero.%s bs=1m count=1000 | openssl dgst -sha512\" % x,stderr=subprocess.STDOUT,shell=True)\n",
    "\n",
    "# And as an example, here's how we can run it:\n",
    "print(zero_to_hash_md5(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run them in parallel..., and ramp them up to see what happens when we run eight at once..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, TimeoutError\n",
    "import time\n",
    "import re\n",
    "\n",
    "def ramp(work_function):\n",
    "    matcher = re.compile(\"\\((\\d+) bytes\\/sec\\)\", re.MULTILINE)\n",
    "    # start worker processes\n",
    "    for size in range(1,9):\n",
    "        with Pool(processes=size) as pool:\n",
    "            start = time.time()\n",
    "\n",
    "            # process in arbitrary order\n",
    "            total_bytes_per_sec = 0\n",
    "            for i in pool.imap_unordered(work_function, range(size)):\n",
    "                #print(i)\n",
    "                total_bytes_per_sec += int(matcher.search(i.decode(\"utf-8\")).group(1))\n",
    "\n",
    "            end = time.time()\n",
    "            print(size, end - start, total_bytes_per_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramping zero-to-null tops out at 4 parallel processes, which make sense because this laptop has four cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.07068204879760742 18059938450\n",
      "2 0.05475807189941406 43874315555\n",
      "3 0.05520486831665039 63935700615\n",
      "4 0.06678485870361328 74882499427\n",
      "5 0.07371282577514648 82503736802\n",
      "6 0.09348011016845703 76472343318\n",
      "7 0.1224210262298584 66292609954\n",
      "8 0.12909793853759766 71127003960\n"
     ]
    }
   ],
   "source": [
    "ramp(zero_to_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly ramping the hash function (no I/O) tops out at 4 cores, at about 950MB/s (about 300MB/s/core but it seems there are some overheads/contention that drops it down slightly when running on all four)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.257678985595703 322724946\n",
      "2 3.259582042694092 649649948\n",
      "3 3.3683509826660156 937987893\n",
      "4 4.3554089069366455 977290258\n",
      "5 5.568627119064331 952358469\n",
      "6 6.776917934417725 941826178\n",
      "7 7.708115100860596 961465940\n",
      "8 8.757246017456055 965819873\n"
     ]
    }
   ],
   "source": [
    "ramp(zero_to_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably, on this laptop, we can stream data into a file at 1,200MB/s (!) which is shared across all cores. Further testing outside of this notebook indicated that this was real I/O speed and not due to files being cached in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0067451000213623 1159417574\n",
      "2 1.9087018966674805 1200274272\n",
      "3 3.00907301902771 1152990121\n",
      "4 4.346774101257324 1006375847\n",
      "5 5.0535972118377686 1102269952\n",
      "6 5.700016021728516 1176617828\n",
      "7 7.790185213088989 1005546787\n",
      "8 9.874356985092163 924100630\n"
     ]
    }
   ],
   "source": [
    "ramp(zero_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, as the I/O is so fast, and the CPU has only four cores, we cannot saturate the bandwith of this machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.3825089931488037 311277138\n",
      "2 3.341557025909424 632465965\n",
      "3 3.7369539737701416 875616590\n",
      "4 4.151122093200684 1053215608\n",
      "5 5.213958024978638 1023341286\n",
      "6 6.675849914550781 954463818\n",
      "7 7.648998022079468 974894618\n",
      "8 9.033785820007324 933483048\n"
     ]
    }
   ],
   "source": [
    "ramp(file_to_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.5086770057678223 301952787\n",
      "2 3.683816909790039 589347858\n",
      "3 4.415766000747681 741013990\n",
      "4 5.2036590576171875 821603443\n",
      "5 5.980767011642456 903950593\n",
      "6 9.35149097442627 676495276\n",
      "7 8.825182914733887 843763533\n",
      "8 10.978984117507935 771277916\n"
     ]
    }
   ],
   "source": [
    "ramp(file_to_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Switching to MD5, the maximum speed is about 2800MB/s (interesting that the performance now tops out at 6, which implies some level of low-level paralellism is allowing this to run even faster!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.138369083404541 492098811\n",
      "2 2.11928391456604 992937563\n",
      "3 2.10658597946167 1499559027\n",
      "4 2.177093029022217 1971763487\n",
      "5 2.237515926361084 2362044839\n",
      "6 2.2916860580444336 2763366883\n",
      "7 2.730095148086548 2892153697\n",
      "8 3.0149781703948975 2852377164\n"
     ]
    }
   ],
   "source": [
    "ramp(zero_to_hash_md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in general, if we're hashing lots of files, we'll tend to run out of I/O before we run out of CPU. However, it depends on lots of things, so it's probably worth benchmarking your own kit.\n",
    "\n",
    "Note that, if the data you are caching is fairly small, your operating system will likely cache it all in RAM rather ran re-reading from disk. In that case you'll get much higher speeds when tests are re-run.\n",
    "\n",
    "Also, there's some subtle issues not investigated here. For example, if you have a lot of small files, then your read speeds can be very low on HDD-based systems, because the disk spends more time seeking to the start of files than it does reading data, and seeking is generally slower than reading.\n",
    "\n",
    "Secondly, on some systems, particularly smaller HDD arrays, I/O speed can drop when you run multiple threads, because the different read requests start to compete with each-other. More heavily RAID-ed systems can compensate for this, but you only have so make HD read heads you can position at one time, and the precise balance will depend on file sizes and how they are distributed across the drives.\n",
    "\n",
    "Generally, with SSD's, these issues are less severe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
